"""
Frame Bridge - Video Processing Module
2ã¤ã®å‹•ç”»ã‚’æœ€é©ãªãƒ•ãƒ¬ãƒ¼ãƒ ã§çµåˆã™ã‚‹ãŸã‚ã®å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import cv2
import numpy as np
from PIL import Image
import tempfile
import os
from skimage.metrics import structural_similarity as ssim
from typing import Tuple, List, Optional, Union
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class VideoProcessor:
    """å‹•ç”»å‡¦ç†ã‚’è¡Œã†ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, similarity_threshold: float = 0.3, exclude_edge_frames: bool = True):
        """
        åˆæœŸåŒ–
        
        Args:
            similarity_threshold: ãƒ•ãƒ¬ãƒ¼ãƒ é¡ä¼¼åº¦ã®é–¾å€¤
            exclude_edge_frames: æœ€åˆã¨æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é™¤å¤–ã™ã‚‹ã‹ã©ã†ã‹
        """
        self.similarity_threshold = similarity_threshold
        self.exclude_edge_frames = exclude_edge_frames
        
    def extract_frames(self, video_path: str, num_frames: int = 20) -> Tuple[Optional[List], Optional[str]]:
        """
        å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã™ã‚‹
        
        Args:
            video_path: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            num_frames: æŠ½å‡ºã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
            
        Returns:
            Tuple[ãƒ•ãƒ¬ãƒ¼ãƒ ãƒªã‚¹ãƒˆ, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸]
        """
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return None, f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ: {video_path}"
            
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            if total_frames == 0:
                return None, "å‹•ç”»ã«ãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
            
            logger.info(f"å‹•ç”» {video_path}: ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•° {total_frames}")
            
            frames = []
            # æœ€åˆã¨æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å«ã‚€ç­‰é–“éš”ã§ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
            frame_indices = np.linspace(0, total_frames-1, num_frames, dtype=int)
            
            for frame_idx in frame_indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                if ret:
                    # BGR to RGBå¤‰æ›
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    frames.append((frame_idx, frame_rgb))
            
            cap.release()
            logger.info(f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†: {len(frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
            return frames, None
            
        except Exception as e:
            logger.error(f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None, f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"

    def calculate_frame_similarity(self, frame1: np.ndarray, frame2: np.ndarray) -> float:
        """
        2ã¤ã®ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹
        
        Args:
            frame1: æ¯”è¼ƒãƒ•ãƒ¬ãƒ¼ãƒ 1
            frame2: æ¯”è¼ƒãƒ•ãƒ¬ãƒ¼ãƒ 2
            
        Returns:
            é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ (0.0-1.0)
        """
        try:
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›
            gray1 = cv2.cvtColor(frame1, cv2.COLOR_RGB2GRAY)
            gray2 = cv2.cvtColor(frame2, cv2.COLOR_RGB2GRAY)
            
            # åŒã˜ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
            h, w = min(gray1.shape[0], gray2.shape[0]), min(gray1.shape[1], gray2.shape[1])
            gray1 = cv2.resize(gray1, (w, h))
            gray2 = cv2.resize(gray2, (w, h))
            
            # SSIMï¼ˆæ§‹é€ çš„é¡ä¼¼æ€§æŒ‡æ¨™ï¼‰ã‚’è¨ˆç®—
            similarity = ssim(gray1, gray2)
            return max(0.0, similarity)  # è² ã®å€¤ã‚’0ã«ã‚¯ãƒªãƒƒãƒ—
            
        except Exception as e:
            logger.error(f"é¡ä¼¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0

    def find_best_connection_frames(self, video1_path: str, video2_path: str) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], float, Optional[str], Tuple[int, int]]:
        """
        2ã¤ã®å‹•ç”»ã®æœ€é©ãªæ¥ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¦‹ã¤ã‘ã‚‹
        å‹•ç”»2ã®æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¨å‹•ç”»1ã®å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰æœ€ã‚‚é¡ä¼¼ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¢ç´¢
        
        Args:
            video1_path: å‹•ç”»1ã®ãƒ‘ã‚¹
            video2_path: å‹•ç”»2ã®ãƒ‘ã‚¹
            
        Returns:
            Tuple[æœ€é©ãƒ•ãƒ¬ãƒ¼ãƒ 1, æœ€é©ãƒ•ãƒ¬ãƒ¼ãƒ 2, é¡ä¼¼åº¦, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸, ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹]
        """
        try:
            # å„å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
            frames1, error1 = self.extract_frames(video1_path, 30)  # ã‚ˆã‚Šå¤šãã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
            if error1:
                return None, None, 0.0, error1, (0, 0)
            
            frames2, error2 = self.extract_frames(video2_path, 10)  # å‹•ç”»2ã¯å°‘ãªã‚ã§OK
            if error2:
                return None, None, 0.0, error2, (0, 0)
            
            # ã‚¨ãƒƒã‚¸ãƒ•ãƒ¬ãƒ¼ãƒ é™¤å¤–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®é©ç”¨
            if self.exclude_edge_frames:
                # æœ€åˆã¨æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é™¤å¤–
                frames1_filtered = frames1[1:-1] if len(frames1) > 2 else frames1
                frames2_filtered = frames2[1:-1] if len(frames2) > 2 else frames2
                logger.info(f"ã‚¨ãƒƒã‚¸ãƒ•ãƒ¬ãƒ¼ãƒ é™¤å¤–: å‹•ç”»1 {len(frames1)} â†’ {len(frames1_filtered)}ãƒ•ãƒ¬ãƒ¼ãƒ , å‹•ç”»2 {len(frames2)} â†’ {len(frames2_filtered)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
            else:
                frames1_filtered = frames1
                frames2_filtered = frames2
                logger.info("ã‚¨ãƒƒã‚¸ãƒ•ãƒ¬ãƒ¼ãƒ é™¤å¤–: ç„¡åŠ¹")
            
            # å‹•ç”»2ã®æœ€åˆã®æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åŸºæº–ã«ã™ã‚‹ï¼ˆã‚ˆã‚Šé«˜ç²¾åº¦ãªæ¢ç´¢ï¼‰
            video2_start_frames = frames2_filtered[:3]  # å‹•ç”»2ã®æœ€åˆã®3ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆã‚¨ãƒƒã‚¸é™¤å¤–å¾Œï¼‰
            
            best_similarity = -1
            best_frame1 = None
            best_frame2 = None
            best_indices = (0, 0)
            
            logger.info(f"ãƒ•ãƒ¬ãƒ¼ãƒ é¡ä¼¼åº¦åˆ†æé–‹å§‹: å‹•ç”»2ã®æœ€åˆã®{len(video2_start_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ã¨å‹•ç”»1ã®{len(frames1_filtered)}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¯”è¼ƒ...")
            
            # å‹•ç”»2ã®å„é–‹å§‹ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã¤ã„ã¦ã€å‹•ç”»1ã®å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã¨æ¯”è¼ƒ
            for j, (idx2, frame2) in enumerate(video2_start_frames):
                logger.info(f"å‹•ç”»2ã®ãƒ•ãƒ¬ãƒ¼ãƒ [{idx2}]ã¨ã®æ¯”è¼ƒé–‹å§‹...")
                
                for i, (idx1, frame1) in enumerate(frames1_filtered):
                    similarity = self.calculate_frame_similarity(frame1, frame2)
                    logger.info(f"  å‹•ç”»1[{idx1}] vs å‹•ç”»2[{idx2}]: é¡ä¼¼åº¦ {similarity:.3f}")
                    
                    if similarity > best_similarity:
                        best_similarity = similarity
                        best_frame1 = frame1
                        best_frame2 = frame2
                        best_indices = (idx1, idx2)
                        logger.info(f"  ğŸŒŸ æ–°ã—ã„æœ€é«˜é¡ä¼¼åº¦: {similarity:.3f} (å‹•ç”»1[{idx1}] â†’ å‹•ç”»2[{idx2}])")
            
            logger.info(f"æœ€é©æ¥ç¶šç‚¹æ¤œå‡ºå®Œäº†: é¡ä¼¼åº¦ {best_similarity:.3f}")
            logger.info(f"æœ€é©çµåˆç‚¹: å‹•ç”»1ã®ãƒ•ãƒ¬ãƒ¼ãƒ [{best_indices[0]}] â†’ å‹•ç”»2ã®ãƒ•ãƒ¬ãƒ¼ãƒ [{best_indices[1]}]")
            
            return best_frame1, best_frame2, best_similarity, None, best_indices
            
        except Exception as e:
            logger.error(f"ãƒ•ãƒ¬ãƒ¼ãƒ æ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {e}")
            return None, None, 0.0, f"ãƒ•ãƒ¬ãƒ¼ãƒ æ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {str(e)}", (0, 0)

    def create_merged_video(self, video1_path: str, video2_path: str, cut_frame1: int, cut_frame2: int, output_path: str) -> Tuple[bool, Optional[str]]:
        """
        2ã¤ã®å‹•ç”»ã‚’æŒ‡å®šã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã§çµåˆã™ã‚‹
        
        Args:
            video1_path: å‹•ç”»1ã®ãƒ‘ã‚¹
            video2_path: å‹•ç”»2ã®ãƒ‘ã‚¹
            cut_frame1: å‹•ç”»1ã®ã‚«ãƒƒãƒˆãƒ•ãƒ¬ãƒ¼ãƒ 
            cut_frame2: å‹•ç”»2ã®ã‚«ãƒƒãƒˆãƒ•ãƒ¬ãƒ¼ãƒ 
            output_path: å‡ºåŠ›ãƒ‘ã‚¹
            
        Returns:
            Tuple[æˆåŠŸãƒ•ãƒ©ã‚°, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸]
        """
        try:
            # å‹•ç”»1ã‚’èª­ã¿è¾¼ã¿
            cap1 = cv2.VideoCapture(video1_path)
            if not cap1.isOpened():
                return False, "å‹•ç”»1ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ"
            
            # å‹•ç”»2ã‚’èª­ã¿è¾¼ã¿
            cap2 = cv2.VideoCapture(video2_path)
            if not cap2.isOpened():
                cap1.release()
                return False, "å‹•ç”»2ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ"
            
            # å‹•ç”»ã®æƒ…å ±ã‚’å–å¾—
            fps1 = cap1.get(cv2.CAP_PROP_FPS)
            width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))
            height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            logger.info(f"å‹•ç”»1æƒ…å ±: {width1}x{height1}, {fps1}fps")
            
            # å‡ºåŠ›å‹•ç”»ã®è¨­å®šï¼ˆæœ€åˆã®å‹•ç”»ã®è¨­å®šã‚’ä½¿ç”¨ï¼‰
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps1, (width1, height1))
            
            # å‹•ç”»1ã®æœ€åˆã‹ã‚‰cut_frame1ã¾ã§
            frame_count = 0
            while frame_count <= cut_frame1:
                ret, frame = cap1.read()
                if not ret:
                    break
                out.write(frame)
                frame_count += 1
            
            logger.info(f"å‹•ç”»1ã‹ã‚‰ {frame_count} ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ")
            
            # å‹•ç”»2ã®cut_frame2ã‹ã‚‰æœ€å¾Œã¾ã§
            cap2.set(cv2.CAP_PROP_POS_FRAMES, cut_frame2)
            frame_count2 = 0
            while True:
                ret, frame = cap2.read()
                if not ret:
                    break
                # ã‚µã‚¤ã‚ºã‚’å‹•ç”»1ã«åˆã‚ã›ã‚‹
                if frame.shape[:2] != (height1, width1):
                    frame = cv2.resize(frame, (width1, height1))
                out.write(frame)
                frame_count2 += 1
            
            logger.info(f"å‹•ç”»2ã‹ã‚‰ {frame_count2} ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ")
            
            # ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾
            cap1.release()
            cap2.release()
            out.release()
            
            logger.info(f"å‹•ç”»çµåˆå®Œäº†: {output_path}")
            return True, None
            
        except Exception as e:
            logger.error(f"å‹•ç”»çµåˆã‚¨ãƒ©ãƒ¼: {e}")
            return False, f"å‹•ç”»çµåˆã‚¨ãƒ©ãƒ¼: {str(e)}"

    def save_frame_as_image(self, frame: np.ndarray, filename: str) -> Optional[str]:
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”»åƒã¨ã—ã¦ä¿å­˜ã™ã‚‹
        
        Args:
            frame: ä¿å­˜ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ 
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        try:
            temp_dir = tempfile.gettempdir()
            file_path = os.path.join(temp_dir, filename)
            
            # PIL Imageã«å¤‰æ›ã—ã¦ä¿å­˜
            pil_image = Image.fromarray(frame)
            pil_image.save(file_path)
            
            logger.info(f"ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒä¿å­˜: {file_path}")
            return file_path
            
        except Exception as e:
            logger.error(f"ç”»åƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def analyze_video_details(self, video_path: str) -> str:
        """
        å‹•ç”»ã®è©³ç´°æƒ…å ±ã‚’åˆ†æã™ã‚‹
        
        Args:
            video_path: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            å‹•ç”»æƒ…å ±ã®æ–‡å­—åˆ—
        """
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return "å‹•ç”»ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ"
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = frame_count / fps if fps > 0 else 0
            
            cap.release()
            
            return f"""ğŸ“¹ å‹•ç”»æƒ…å ±:
â€¢ è§£åƒåº¦: {width} x {height}
â€¢ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ: {fps:.2f} FPS
â€¢ ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}
â€¢ å†ç”Ÿæ™‚é–“: {duration:.2f} ç§’
â€¢ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {os.path.getsize(video_path) / (1024*1024):.1f} MB"""
            
        except Exception as e:
            logger.error(f"å‹•ç”»åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return f"å‹•ç”»åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"


class FrameBridge:
    """Frame Bridge ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, exclude_edge_frames: bool = True):
        """
        åˆæœŸåŒ–
        
        Args:
            exclude_edge_frames: æœ€åˆã¨æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é™¤å¤–ã™ã‚‹ã‹ã©ã†ã‹
        """
        self.processor = VideoProcessor(exclude_edge_frames=exclude_edge_frames)
    
    def process_video_bridge(self, video1_path: str, video2_path: str) -> Tuple[str, Optional[str], Optional[str], Optional[str], float]:
        """
        2ã¤ã®å‹•ç”»ã‚’åˆ†æã—ã¦æœ€é©ãªçµåˆç‚¹ã‚’è¦‹ã¤ã‘ã€çµåˆã™ã‚‹
        
        Args:
            video1_path: å‹•ç”»1ã®ãƒ‘ã‚¹
            video2_path: å‹•ç”»2ã®ãƒ‘ã‚¹
            
        Returns:
            Tuple[çµæœãƒ†ã‚­ã‚¹ãƒˆ, çµåˆå‹•ç”»ãƒ‘ã‚¹, ãƒ•ãƒ¬ãƒ¼ãƒ 1ãƒ‘ã‚¹, ãƒ•ãƒ¬ãƒ¼ãƒ 2ãƒ‘ã‚¹, é¡ä¼¼åº¦]
        """
        if not video1_path or not video2_path:
            return "2ã¤ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™ã€‚", None, None, None, 0.0
        
        if not os.path.exists(video1_path) or not os.path.exists(video2_path):
            return "æŒ‡å®šã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", None, None, None, 0.0
        
        try:
            logger.info("å‹•ç”»åˆ†æé–‹å§‹...")
            
            # æœ€é©ãªæ¥ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¦‹ã¤ã‘ã‚‹
            frame1, frame2, similarity, error, indices = self.processor.find_best_connection_frames(video1_path, video2_path)
            
            if error:
                return f"ã‚¨ãƒ©ãƒ¼: {error}", None, None, None, 0.0
            
            logger.info("æœ€é©ãªæ¥ç¶šç‚¹ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”»åƒã¨ã—ã¦ä¿å­˜
            frame1_path = self.processor.save_frame_as_image(frame1, "connection_frame1.png")
            frame2_path = self.processor.save_frame_as_image(frame2, "connection_frame2.png")
            
            logger.info("å‹•ç”»çµåˆé–‹å§‹...")
            
            # çµåˆå‹•ç”»ã‚’ä½œæˆ
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, "merged_video.mp4")
            
            # æœ€é©ãªãƒ•ãƒ¬ãƒ¼ãƒ ã§çµåˆ
            success, merge_error = self.processor.create_merged_video(
                video1_path, video2_path, indices[0], indices[1], output_path
            )
            
            if not success:
                return f"å‹•ç”»çµåˆã‚¨ãƒ©ãƒ¼: {merge_error}", None, None, None, similarity
            
            # å“è³ªè©•ä¾¡
            quality = self._evaluate_quality(similarity)
            
            result_text = f"""ğŸ¬ å‹•ç”»çµåˆå®Œäº†ï¼

ğŸ“Š åˆ†æçµæœ:
â€¢ ãƒ•ãƒ¬ãƒ¼ãƒ é¡ä¼¼åº¦: {similarity:.3f}
â€¢ æ¥ç¶šå“è³ª: {quality}
â€¢ çµåˆãƒ•ãƒ¬ãƒ¼ãƒ : å‹•ç”»1[{indices[0]}] â†’ å‹•ç”»2[{indices[1]}]

ğŸ’¡ çµåˆæƒ…å ±:
â€¢ å‹•ç”»1ã®æœ€é©ãªçµ‚äº†ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¤œå‡º
â€¢ å‹•ç”»2ã®æœ€é©ãªé–‹å§‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¤œå‡º
â€¢ ã‚¹ãƒ ãƒ¼ã‚ºãªæ¥ç¶šã‚’å®Ÿç¾

ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(output_path)}"""
            
            logger.info("å‡¦ç†å®Œäº†")
            return result_text, output_path, frame1_path, frame2_path, similarity
            
        except Exception as e:
            logger.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}", None, None, None, 0.0
    
    def _evaluate_quality(self, similarity: float) -> str:
        """é¡ä¼¼åº¦ã‹ã‚‰å“è³ªã‚’è©•ä¾¡"""
        if similarity > 0.8:
            return "å„ªç§€ ğŸŒŸ"
        elif similarity > 0.6:
            return "è‰¯å¥½ âœ…"
        elif similarity > 0.4:
            return "æ™®é€š âš¡"
        else:
            return "è¦ç¢ºèª âš ï¸"